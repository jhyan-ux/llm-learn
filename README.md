# LLMå­¦ä¹ é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å­¦ä¹ å’Œå®ç°çš„é¡¹ç›®ä»“åº“ã€‚

## é¡¹ç›®ç»“æ„

```
LLM/
â”œâ”€â”€ transformer/          # Transformeræ¶æ„å®ç°
â”‚   â”œâ”€â”€ transformer.py   # å®Œæ•´çš„Transformer Encoderå®ç°
â”‚   â”œâ”€â”€ pe_demo.py       # Position Encodingæ¼”ç¤º
â”‚   â””â”€â”€ ...              # å…¶ä»–ç›¸å…³æ–‡ä»¶
â””â”€â”€ README.md            # é¡¹ç›®è¯´æ˜
```

## Transformerå®ç°

- âœ… **MultiHeadAttention** - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
- âœ… **PositionEncoding** - ä½ç½®ç¼–ç 
- âœ… **FeedForward** - å‰é¦ˆç¥ç»ç½‘ç»œ
- âœ… **EncoderLayer** - ç¼–ç å™¨å±‚
- âœ… **TransformerEncoder** - å®Œæ•´çš„Transformerç¼–ç å™¨

### ç‰¹ç‚¹

- ğŸ”¥ é‡‡ç”¨ç°ä»£Pre-LayerNormæ¶æ„
- ğŸ”¥ å®Œæ•´çš„æ®‹å·®è¿æ¥å’ŒDropoutæ­£åˆ™åŒ–
- ğŸ”¥ æ”¯æŒä»»æ„å±‚æ•°å’Œç»´åº¦é…ç½®
- ğŸ”¥ GPUå…¼å®¹è®¾è®¡

## ä½¿ç”¨æ–¹æ³•

```python
from transformer.transformer import TransformerEncoder

# åˆ›å»ºTransformeræ¨¡å‹
model = TransformerEncoder(
    vocab_size=1000,
    d_model=512,
    num_heads=8,
    d_ff=2048,
    num_layers=6,
    dropout=0.1
)

# å‰å‘ä¼ æ’­
token_ids = torch.randint(0, 1000, (batch_size, seq_length))
output = model(token_ids)
```

## å­¦ä¹ èµ„æº

- ğŸ“š [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - TransformeråŸå§‹è®ºæ–‡
- ğŸ“ è¯¦ç»†çš„ä»£ç æ³¨é‡Šå’Œç»´åº¦æ ‡æ³¨
- ğŸ’¡ å®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹

## ç¯å¢ƒè¦æ±‚

- Python 3.7+
- PyTorch 1.8+

## ä½œè€…

è®¡ç®—æœºè§†è§‰ç ”ç©¶ç”Ÿï¼Œä¸“æ³¨äºLLMå­¦ä¹ ä¸å®ç°

---

*è¿™ä¸ªé¡¹ç›®æ˜¯å­¦ä¹ Transformeræ¶æ„çš„å®Œæ•´å®ç°ï¼Œä»é›¶å¼€å§‹æ„å»ºï¼ŒåŒ…å«è¯¦ç»†çš„æ•™å­¦æ€§æ³¨é‡Šã€‚* 